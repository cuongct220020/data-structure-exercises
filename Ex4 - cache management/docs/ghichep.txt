Bộ nhớ Cache là bộ nhớ giới hạn về dung lượng lưu trữ, tuy nhiên truy cập rất nhanh, nhanh hơn nhiều hơn so với bộ nhớ vật lý (RAM) thông thường. Có các chiến lược quản lý bộ nhớ Cache sau: 
    + Least-Recently Used Cache (LRU Cache): Lựa chọn nạn nhân là cache được sử dụng ở lần cách xa nhất.
    + Most-Recently Used Cache (MRU Cache): Lựa chọn nạn nhân là cache được sử dụng ở lần gần nhất.
    + Most-Frequently Used Cache (MFU Cache): Lựa chọn nạn nhân là cache được sử dụng với tần suất lớn nhất. Nếu hai nạn nhân có cùng tần suất thì sử dụng chiến lược FIFO để lựa chọn. 

Cài đặt LRUCache sử dụng: Danh sách liên kết đôi và bảng băm.
    + Sử dụng danh sách liên kết đôi giúp quản lý thứ tự dễ dàng hơn, thông thường duyệt danh sách liên kết đơn thì thao tác vào cỡ O(n), danh sách liên kết đôi sẽ khắc phục vấn đề này bằng hai con trỏ. Thao tác thêm, xoá là O(1)
    + Sử dụng bảng băm để có thể kiểm tra dễ dàng hơn, nhanh hơn xem Cache có tồn tại trong khối quản lý Cache hay không? Thao tác kiểm tra là O(1)

Cơ chế chung: Với mỗi request, nếu là:
    + Cache Hit: Cập nhật giá trị (value) và độ ưu tiên (priority) của phần tử trong cache 
    + Cache Miss: Tạo phần tử mới và thêm vào khối quản lý Cache, nếu khối quản lý Cache đã đầy thì sử dụng một trong ba chiến lược lựa chọn nạn nhân: LRU, MRU, MFU.
